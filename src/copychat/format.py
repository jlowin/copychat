from pathlib import Path
from typing import Optional
from os.path import commonpath
from datetime import datetime
import tiktoken


def guess_language(file_path: Path) -> Optional[str]:
    """Guess the programming language based on file extension."""
    ext = file_path.suffix.lower()

    # Common language mappings
    language_map = {
        ".py": "python",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "jsx",
        ".tsx": "tsx",
        ".html": "html",
        ".css": "css",
        ".scss": "scss",
        ".rs": "rust",
        ".go": "go",
        ".java": "java",
        ".cpp": "cpp",
        ".c": "c",
        ".h": "c",
        ".hpp": "cpp",
        ".rb": "ruby",
        ".php": "php",
        ".sh": "bash",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".json": "json",
        ".md": "markdown",
        ".sql": "sql",
        ".r": "r",
        ".swift": "swift",
        ".kt": "kotlin",
        ".kts": "kotlin",
        ".scala": "scala",
        ".pl": "perl",
        ".pm": "perl",
    }

    return language_map.get(ext)


def format_file(file_path: Path, root_path: Path, content: Optional[str] = None) -> str:
    """Format a single file as XML-style markdown."""
    try:
        # Use provided content or read from file
        if content is None:
            content = file_path.read_text()

        # Use string paths for comparison to handle symlinks and different path formats
        file_str = str(file_path.absolute())
        root_str = str(root_path)

        # Remove the root path and any leading slashes
        rel_path = file_str[len(root_str) :].lstrip("/\\")
        language = guess_language(file_path)

        # Build the XML tag with attributes
        tag_attrs = [f'path="{rel_path}"']
        if language:
            tag_attrs.append(f'language="{language}"')

        attrs_str = " ".join(tag_attrs)

        return f"""<file {attrs_str}>
{content}
</file>"""

    except Exception as e:
        return f"<!-- Error processing {file_path}: {str(e)} -->"


def create_header(files: list[Path], root_path: Path) -> str:
    """Create a header with metadata about the export."""
    # Change to UTC timestamp
    timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")

    return f"""<!--
Generated by copychat on {timestamp}
Root path: {root_path}
Files: {len(files)}

File list:
{chr(10).join(f'- {f.relative_to(root_path)}' for f in sorted(files))}
-->

"""


def estimate_tokens(text: str) -> int:
    """Estimate the number of tokens in the text using GPT tokenizer."""
    try:
        # Using cl100k_base (used by GPT-4, Claude)
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except Exception:
        # Fallback to rough estimate if tiktoken fails
        return len(text) // 4  # Rough estimate: ~4 chars per token


def format_files(files: list[tuple[Path, str]]) -> str:
    """Format files into markdown with XML-style tags.

    Args:
        files: List of (path, content) tuples to format
    """
    if not files:
        return "<!-- No files found matching criteria -->\n"

    # Find common root path using os.path.commonpath
    paths = [f[0] for f in files]
    str_paths = [str(f.absolute()) for f in paths]
    root_path = Path(commonpath(str_paths))

    # Create header
    result = [create_header(paths, root_path)]

    # Format each file
    for file_path, content in files:
        result.append(format_file(file_path, root_path, content))

    final_result = "\n".join(result)
    char_count = len(final_result)
    token_estimate = estimate_tokens(final_result)

    # Add character and token count to header
    final_result = final_result.replace(
        "-->",
        f"\nCharacters: {char_count:,}\nEstimated tokens: {token_estimate:,}\n-->",
    )

    return final_result

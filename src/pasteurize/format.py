from pathlib import Path
from typing import Optional
import sys
from os.path import commonpath
from datetime import datetime
import tiktoken


def guess_language(file_path: Path) -> Optional[str]:
    """Guess the programming language based on file extension."""
    ext = file_path.suffix.lower()

    # Common language mappings
    language_map = {
        ".py": "python",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "jsx",
        ".tsx": "tsx",
        ".html": "html",
        ".css": "css",
        ".scss": "scss",
        ".rs": "rust",
        ".go": "go",
        ".java": "java",
        ".cpp": "cpp",
        ".c": "c",
        ".h": "c",
        ".hpp": "cpp",
        ".rb": "ruby",
        ".php": "php",
        ".sh": "bash",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".json": "json",
        ".md": "markdown",
        ".sql": "sql",
        ".r": "r",
        ".swift": "swift",
        ".kt": "kotlin",
        ".kts": "kotlin",
        ".scala": "scala",
        ".pl": "perl",
        ".pm": "perl",
    }

    return language_map.get(ext)


def format_file(file_path: Path, root_path: Path, verbose: bool = False) -> str:
    """Format a single file as XML-style markdown with line numbers."""
    if verbose:
        print(f"Formatting file: {file_path}", file=sys.stderr)

    try:
        content = file_path.read_text()
        # Use string paths for comparison to handle symlinks and different path formats
        file_str = str(file_path.absolute())
        root_str = str(root_path)

        # Remove the root path and any leading slashes
        rel_path = file_str[len(root_str) :].lstrip("/\\")
        language = guess_language(file_path)

        # Build the XML tag with attributes
        tag_attrs = [f'path="{rel_path}"']
        if language:
            tag_attrs.append(f'language="{language}"')

        attrs_str = " ".join(tag_attrs)

        # Add line numbers to content
        numbered_lines = []
        for i, line in enumerate(content.splitlines(), 1):
            numbered_lines.append(f"{i}|{line}")
        numbered_content = "\n".join(numbered_lines)

        if verbose:
            print(f"Successfully formatted: {rel_path}", file=sys.stderr)

        return f"""<file {attrs_str}>
{numbered_content}
</file>"""

    except Exception as e:
        if verbose:
            print(f"Error formatting {file_path}: {e}", file=sys.stderr)
        return f"<!-- Error processing {file_path}: {str(e)} -->"


def create_header(files: list[Path], root_path: Path) -> str:
    """Create a header with metadata about the export."""
    # Change to UTC timestamp
    timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")

    return f"""<!--
Generated by pasteurize on {timestamp}
Root path: {root_path}
Files: {len(files)}

File list:
{chr(10).join(f'- {f.relative_to(root_path)}' for f in sorted(files))}
-->

"""


def estimate_tokens(text: str) -> int:
    """Estimate the number of tokens in the text using GPT tokenizer."""
    try:
        # Using cl100k_base (used by GPT-4, Claude)
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except Exception:
        # Fallback to rough estimate if tiktoken fails
        return len(text) // 4  # Rough estimate: ~4 chars per token


def format_files(files: list[Path], verbose: bool = False) -> str:
    """
    Format files into markdown with XML-style tags.

    Args:
        files: List of file paths to format
        verbose: Whether to print debug information

    Returns:
        Formatted markdown string
    """
    if verbose:
        print(f"\nStarting to format {len(files)} files...", file=sys.stderr)

    if not files:
        return "<!-- No files found matching criteria -->\n"

    # Find common root path using os.path.commonpath
    str_paths = [str(f.absolute()) for f in files]
    root_path = Path(commonpath(str_paths))
    if verbose:
        print(f"Using root path: {root_path}", file=sys.stderr)

    # Create header
    result = [create_header(files, root_path)]

    # Format each file
    for i, file_path in enumerate(files, 1):
        if verbose and i % 10 == 0:
            print(f"Formatted {i}/{len(files)} files...", file=sys.stderr)
        result.append(format_file(file_path, root_path, verbose))

    if verbose:
        print("Formatting complete, joining results...", file=sys.stderr)

    final_result = "\n".join(result)
    char_count = len(final_result)
    token_estimate = estimate_tokens(final_result)

    # Add character and token count to header
    final_result = final_result.replace(
        "-->",
        f"\nCharacters: {char_count:,}\nEstimated tokens: {token_estimate:,}\n-->",
    )

    if verbose:
        print(
            f"Final output: {char_count:,} characters, ~{token_estimate:,} tokens",
            file=sys.stderr,
        )

    return final_result
